Modify class Attention in timm.models.vision_transformer such that it return attention maps, then forward encoder so that it return attention map of the last layer specifically
